{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sweetviz in /home/marlesson/anaconda3/lib/python3.7/site-packages (1.1.1)\n",
      "Requirement already satisfied: tqdm>=4.43.0 in /home/marlesson/anaconda3/lib/python3.7/site-packages (from sweetviz) (4.49.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/marlesson/anaconda3/lib/python3.7/site-packages (from sweetviz) (1.5.0)\n",
      "Requirement already satisfied: matplotlib>=3.1.3 in /home/marlesson/anaconda3/lib/python3.7/site-packages (from sweetviz) (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/marlesson/anaconda3/lib/python3.7/site-packages (from sweetviz) (1.19.0)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in /home/marlesson/anaconda3/lib/python3.7/site-packages (from sweetviz) (2.11.2)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in /home/marlesson/anaconda3/lib/python3.7/site-packages (from sweetviz) (1.1.2)\n",
      "Requirement already satisfied: importlib-resources>=1.2.0 in /home/marlesson/anaconda3/lib/python3.7/site-packages (from sweetviz) (3.2.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/marlesson/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.1.3->sweetviz) (2.3.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/marlesson/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.1.3->sweetviz) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/marlesson/.local/lib/python3.7/site-packages (from matplotlib>=3.1.3->sweetviz) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/marlesson/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.1.3->sweetviz) (0.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/marlesson/anaconda3/lib/python3.7/site-packages (from jinja2>=2.11.1->sweetviz) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/marlesson/anaconda3/lib/python3.7/site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2018.7)\n",
      "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /home/marlesson/anaconda3/lib/python3.7/site-packages (from importlib-resources>=1.2.0->sweetviz) (3.4.0)\n",
      "Requirement already satisfied: setuptools in /home/marlesson/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.1.3->sweetviz) (40.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/marlesson/.local/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib>=3.1.3->sweetviz) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sweetviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionId</th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "      <th>timeframe</th>\n",
       "      <th>eventdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81766</td>\n",
       "      <td>526309</td>\n",
       "      <td>2016-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31331</td>\n",
       "      <td>1031018</td>\n",
       "      <td>2016-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32118</td>\n",
       "      <td>243569</td>\n",
       "      <td>2016-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9654</td>\n",
       "      <td>75848</td>\n",
       "      <td>2016-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32627</td>\n",
       "      <td>1112408</td>\n",
       "      <td>2016-05-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sessionId  userId  itemId  timeframe   eventdate\n",
       "0          1     NaN   81766     526309  2016-05-09\n",
       "1          1     NaN   31331    1031018  2016-05-09\n",
       "2          1     NaN   32118     243569  2016-05-09\n",
       "3          1     NaN    9654      75848  2016-05-09\n",
       "4          1     NaN   32627    1112408  2016-05-09"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_PATH: str = os.environ[\n",
    "    \"OUTPUT_PATH\"\n",
    "] if \"OUTPUT_PATH\" in os.environ else os.path.join(\"output\")\n",
    "BASE_DIR: str = os.path.join(OUTPUT_PATH, \"diginetica\")\n",
    "DATASET_DIR: str = os.path.join(OUTPUT_PATH, \"diginetica\", \"dataset\")\n",
    "\n",
    "BASE_DATASET_FILE : str = os.path.join(OUTPUT_PATH, \"diginetica\", \"dataset-train-diginetica\", 'train-item-views.csv')\n",
    "\n",
    "df = pd.read_csv(BASE_DATASET_FILE, sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['eventdate'] = pd.to_datetime(df['eventdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475c848ebded44eda8853131fc238536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=6.0), HTML(value='')), layout=Layout(disp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3f37c3df6a4c289cbd3f181529ba14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=5.0), HTML(value='')), layout=Layout(disp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0f281fee0e4565b3d16388e51210d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1.0), HTML(value='')), layout=Layout(disp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Report Advertising.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "# importing sweetviz\n",
    "import sweetviz as sv\n",
    "#analyzing the dataset\n",
    "advert_report = sv.analyze(df)\n",
    "#display the report\n",
    "advert_report.show_html('Advertising.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a11aeea66fc4012b34420a87565d9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Summarize dataset', max=19.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marlesson/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-5af8ce0c51a9>\", line 3, in <module>\n",
      "    profile\n",
      "  File \"/home/marlesson/.local/lib/python3.7/site-packages/IPython/core/displayhook.py\", line 262, in __call__\n",
      "    format_dict, md_dict = self.compute_format_data(result)\n",
      "  File \"/home/marlesson/.local/lib/python3.7/site-packages/IPython/core/displayhook.py\", line 151, in compute_format_data\n",
      "    return self.shell.display_formatter.format(result)\n",
      "  File \"/home/marlesson/.local/lib/python3.7/site-packages/IPython/core/formatters.py\", line 180, in format\n",
      "    data = formatter(obj)\n",
      "  File \"</home/marlesson/.local/lib/python3.7/site-packages/decorator.py:decorator-gen-9>\", line 2, in __call__\n",
      "  File \"/home/marlesson/.local/lib/python3.7/site-packages/IPython/core/formatters.py\", line 224, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "  File \"/home/marlesson/.local/lib/python3.7/site-packages/IPython/core/formatters.py\", line 345, in __call__\n",
      "    return method()\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/site-packages/pandas_profiling/profile_report.py\", line 397, in _repr_html_\n",
      "    self.to_notebook_iframe()\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/site-packages/pandas_profiling/profile_report.py\", line 377, in to_notebook_iframe\n",
      "    display(get_notebook_iframe(self))\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/site-packages/pandas_profiling/report/presentation/flavours/widget/notebook.py\", line 65, in get_notebook_iframe\n",
      "    output = get_notebook_iframe_srcdoc(profile)\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/site-packages/pandas_profiling/report/presentation/flavours/widget/notebook.py\", line 23, in get_notebook_iframe_srcdoc\n",
      "    src = html.escape(profile.to_html())\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/site-packages/pandas_profiling/profile_report.py\", line 348, in to_html\n",
      "    return self.html\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/site-packages/pandas_profiling/profile_report.py\", line 168, in html\n",
      "    self._html = self._render_html()\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/site-packages/pandas_profiling/profile_report.py\", line 275, in _render_html\n",
      "    report = self.report\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/site-packages/pandas_profiling/profile_report.py\", line 162, in report\n",
      "    self._report = get_report_structure(self.description_set)\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/site-packages/pandas_profiling/profile_report.py\", line 143, in description_set\n",
      "    self._description_set = describe_df(self.title, self.df)\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/site-packages/pandas_profiling/model/describe.py\", line 82, in describe\n",
      "    df, variables, correlation_name\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/site-packages/pandas_profiling/model/correlations.py\", line 131, in calculate_correlation\n",
      "    correlation = df.corr(method=correlation_name)\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\", line 8152, in corr\n",
      "    c = corrf(ac, bc)\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/site-packages/pandas/core/nanops.py\", line 1360, in func\n",
      "    return kendalltau(a, b)[0]\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py\", line 4457, in kendalltau\n",
      "    perm = np.argsort(x, kind='mergesort')\n",
      "  File \"<__array_function__ internals>\", line 6, in argsort\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\", line 1107, in argsort\n",
      "    return _wrapfunc(a, 'argsort', axis=axis, kind=kind, order=order)\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\", line 58, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marlesson/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marlesson/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/marlesson/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/marlesson/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/posixpath.py\", line 428, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/home/marlesson/anaconda3/lib/python3.7/posixpath.py\", line 89, in join\n",
      "    elif not path or path.endswith(sep):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(df, explorative=True)\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sum = sum\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import collect_set, collect_list, lit, sum, udf, concat_ws, col, count, abs, date_format, \\\n",
    "    from_utc_timestamp, expr, min, max\n",
    "from pyspark.sql.functions import col, udf, size\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import explode, posexplode\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pad_history = F.udf(\n",
    "    lambda arr, size: list(reversed(([0] * (size - len(arr[:-1][:size])) + arr[:-1][:size]))), \n",
    "    ArrayType(IntegerType())\n",
    ")\n",
    "\n",
    "def sample_items(item, item_list, size_available_list):\n",
    "    return random.sample(item_list, size_available_list - 1) + [item]\n",
    "\n",
    "def udf_sample_items(item_list, size_available_list):\n",
    "    return udf(lambda item: sample_items(item, item_list, size_available_list), ArrayType(IntegerType()))\n",
    "\n",
    "\n",
    "def concat(type):\n",
    "    def concat_(*args):\n",
    "        return list(set(chain.from_iterable((arg if arg else [] for arg in args))))\n",
    "    return udf(concat_, ArrayType(type))\n",
    "\n",
    "\n",
    "OUTPUT_PATH: str = os.environ[\n",
    "    \"OUTPUT_PATH\"\n",
    "] if \"OUTPUT_PATH\" in os.environ else os.path.join(\"output\")\n",
    "BASE_DIR: str = os.path.join(OUTPUT_PATH, \"diginetica\")\n",
    "DATASET_DIR: str = os.path.join(OUTPUT_PATH, \"diginetica\", \"dataset\")\n",
    "\n",
    "BASE_DATASET_FILE : str = os.path.join(OUTPUT_PATH, \"diginetica\", \"dataset-train-diginetica\", 'train-item-views.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"delimiter\", \";\").csv(BASE_DATASET_FILE, header=True, inferSchema=True)\n",
    "df = df.withColumnRenamed(\"sessionId\", \"SessionID\")\\\n",
    "    .withColumnRenamed(\"eventdate\", \"Timestamp\")\\\n",
    "    .withColumnRenamed(\"itemId\", \"ItemID\")\\\n",
    "    .withColumn(\"Timestamp\", (col(\"Timestamp\").cast(\"long\") + col(\"timeframe\").cast(\"long\")/1000).cast(\"timestamp\"))\\\n",
    "    .orderBy(col('Timestamp'), col('SessionID'), col('timeframe')).select(\"SessionID\", \"ItemID\", \"Timestamp\", \"timeframe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(10, False), df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate item in that same session\n",
    "df = df.dropDuplicates(['SessionID', 'ItemID'])\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra\n",
    "sample_days = 8\n",
    "minimum_interactions = 5\n",
    "\n",
    "# filter date\n",
    "max_timestamp  = df.select(max(col('Timestamp'))).collect()[0]['max(Timestamp)']\n",
    "init_timestamp = max_timestamp - timedelta(days = sample_days)\n",
    "df             = df.filter(col('Timestamp') >= init_timestamp).cache()\n",
    "\n",
    "\n",
    "# Filter minin interactions\n",
    "df_item    = df.groupBy(\"ItemID\").count()\n",
    "df_item    = df_item.filter(col('count') >= minimum_interactions)\n",
    "\n",
    "\n",
    "# Filter session size\n",
    "df_session    = df.groupBy(\"SessionID\").count()\n",
    "df_session    = df_session.filter(col('count') >= 2)\n",
    "\n",
    "df = df \\\n",
    "    .join(df_item, \"ItemID\", how=\"inner\") \\\n",
    "    .join(df_session, \"SessionID\", how=\"inner\")\n",
    "\n",
    "df.orderBy(col('SessionID'), col('Timestamp')).show(10, False), df.count()\n",
    "\n",
    "# return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item    = df.groupBy(\"ItemID\").count()\n",
    "df_item.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add history\n",
    "history_window = 10\n",
    "##\n",
    "\n",
    "w = Window.partitionBy('SessionID').orderBy('Timestamp')#.rangeBetween(Window.currentRow, 5)\n",
    "\n",
    "df = df.withColumn(\n",
    "    'ItemIDHistory', F.collect_list('ItemID').over(w)\n",
    ").where(size(col(\"ItemIDHistory\")) >= 2)#\\\n",
    "\n",
    "df = df.withColumn('ItemIDHistory', pad_history(df.ItemIDHistory, lit(history_window)))\n",
    "df.orderBy(col('SessionID'), col('Timestamp')).show(10, False), df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.toPandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_test = 1\n",
    "timestamp_property = 'Timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cutoff_date = df[timestamp_property].iloc[-1] - pd.Timedelta(days=days_test)\n",
    "cutoff_date, df[timestamp_property].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[timestamp_property] >= cutoff_date].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/media/workspace/triplet_session/output/diginetica/dataset/test_0.20_test=time_42_SessionInteractionDataFrame_____SessionID_6cdc23187f.csv')\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parans\n",
    "min_itens_per_session  = 2\n",
    "max_itens_per_session  = 15\n",
    "min_itens_interactions = 3 # Tupla interactions\n",
    "max_relative_pos       = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"delimiter\", \";\").csv(BASE_DATASET_FILE, header=True, inferSchema=True)\n",
    "df = df.withColumnRenamed(\"sessionId\", \"SessionID\")\\\n",
    "    .withColumnRenamed(\"eventdate\", \"Timestamp\")\\\n",
    "    .withColumnRenamed(\"itemId\", \"ItemID\")\\\n",
    "    .withColumn(\"Timestamp\", (col(\"Timestamp\").cast(\"long\") + col(\"timeframe\").cast(\"long\")/1000).cast(\"timestamp\"))\\\n",
    "    .orderBy(col('Timestamp'), col('SessionID'), col('timeframe')).select(\"SessionID\", \"ItemID\", \"Timestamp\", \"timeframe\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate item in that same session\n",
    "df       = df.dropDuplicates(['SessionID', 'ItemID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra\n",
    "sample_days = 8\n",
    "minimum_interactions = 5\n",
    "\n",
    "# filter date\n",
    "max_timestamp  = df.select(max(col('Timestamp'))).collect()[0]['max(Timestamp)']\n",
    "init_timestamp = max_timestamp - timedelta(days = sample_days)\n",
    "df             = df.filter(col('Timestamp') >= init_timestamp).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df       = df.groupby(\"SessionID\").agg(\n",
    "            max(\"Timestamp\").alias(\"Timestamp\"),\n",
    "            collect_list(\"ItemID\").alias(\"ItemIDs\"),\n",
    "            count(\"ItemID\").alias(\"total\"))\n",
    "\n",
    "df.show(10), df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Interactions\n",
    "df = df.filter(df.total >= min_itens_per_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = df.select(col('SessionID').alias('_SessionID'),\n",
    "                            posexplode(df.ItemIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos.show(10), df_pos.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode A\n",
    "df = df.withColumn(\"ItemID_A\", explode(df.ItemIDs))\n",
    "df = df.join(df_pos,\n",
    "            (df.SessionID == df_pos._SessionID) & (df.ItemID_A == df_pos.col))\\\n",
    "        .select('SessionID', 'Timestamp', 'ItemID_A', 'pos', 'ItemIDs')\\\n",
    "        .withColumnRenamed('pos', 'pos_A')\n",
    "\n",
    "df.show(10), df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode B\n",
    "df = df.withColumn(\"ItemID_B\", explode(df.ItemIDs))\n",
    "df = df.join(df_pos,\n",
    "            (df.SessionID == df_pos._SessionID) & (df.ItemID_B == df_pos.col))\\\n",
    "        .withColumnRenamed('pos', 'pos_B')\n",
    "df.show(10), df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"relative_pos\", abs(df.pos_A - df.pos_B))\n",
    "df.show(10), df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('SessionID', 'Timestamp', 'ItemID_A', 'pos_A', \n",
    "                        'ItemID_B', 'pos_B', 'relative_pos')\\\n",
    "                .distinct()\\\n",
    "                .filter(df.ItemID_A != df.ItemID_B)\n",
    "df.show(10), df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_df_tuple_probs\n",
    "\n",
    "df_tuple_count  = df.groupby(\"ItemID_A\",\"ItemID_B\").count()\n",
    "df_count        = df.groupby(\"ItemID_A\").count()\\\n",
    "                    .withColumnRenamed(\"count\", \"total\")\\\n",
    "                    .withColumnRenamed(\"ItemID_A\", \"_ItemID_A\")\n",
    "\n",
    "df_join         = df_tuple_count.join(df_count, df_tuple_count.ItemID_A == df_count._ItemID_A)\n",
    "df_join         = df_join.withColumn(\"prob\", col(\"count\")/col(\"total\"))\n",
    "\n",
    "df_join  = df_join.select(\"ItemID_A\", 'ItemID_B', 'count', 'total', 'prob')\\\n",
    "            .withColumnRenamed(\"ItemID_A\", \"_ItemID_A\")\\\n",
    "            .withColumnRenamed(\"ItemID_B\", \"_ItemID_B\")\\\n",
    "            .withColumnRenamed(\"count\", \"total_ocr_dupla\")\\\n",
    "            .withColumnRenamed(\"total\", \"total_ocr\")\n",
    "\n",
    "df_join.show(10), df_join.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_probs = df_join\n",
    "df = df.join(df_probs, (df.ItemID_A == df_probs._ItemID_A) & (df.ItemID_B == df_probs._ItemID_B))\n",
    "df.show(10), df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#add_positive_interactions\n",
    "pos_max_deep = 1\n",
    "\n",
    "def serach_positive(uid, df, max_deep = 1, deep = 0, list_pos = []):\n",
    "    if uid not in list_pos:\n",
    "        list_pos.append(uid)\n",
    "        #print(list_pos)\n",
    "       \n",
    "        if deep >= max_deep:\n",
    "            return df.loc[uid].sub_a_b\n",
    "        else:\n",
    "            l = [serach_positive(i, df, max_deep, deep+1, list_pos) for i in df.loc[uid].sub_a_b]\n",
    "            l.append(df.loc[uid].sub_a_b)\n",
    "            return list_sum(l, [])\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "    \n",
    "# Filter more then 1 ocurrence for positive interactions\n",
    "df_positive = df.filter(col(\"total_ocr_dupla\") > 1)\n",
    "\n",
    "df_positive = df_positive\\\n",
    "    .groupby(\"ItemID_A\")\\\n",
    "    .agg(F.collect_set(\"ItemID_B\").alias(\"sub_a_b\"))\n",
    "\n",
    "# df_b = df\\\n",
    "#     .groupby(\"ItemID_B\")\\\n",
    "#     .agg(F.collect_set(\"ItemID_A\").alias(\"sub_b\"))\n",
    "\n",
    "# df = df.join(df_a, \"ItemID_A\").join(df_b, \"ItemID_B\").cache()\n",
    "\n",
    "# concat_int_arrays = concat(IntegerType())\n",
    "# df = df.withColumn(\"sub_a_b\", concat_int_arrays(\"sub_a\", \"sub_b\"))#.show(truncate=False)\n",
    "# return df\n",
    "df_positive = df_positive.withColumnRenamed(\"ItemID_A\", \"ItemID\")\n",
    "#df = df.withColumn(\"ItemID_COPY\",df.ItemID)\n",
    "\n",
    "df_positive = df_positive.toPandas().set_index('ItemID')\n",
    "print(df_positive)\n",
    "\n",
    "sub_pos = []\n",
    "for i, row in df_positive.iterrows():\n",
    "    l = serach_positive(row.name, df_positive, max_deep = pos_max_deep, deep=0, list_pos=[])\n",
    "    sub_pos.append(list(np.unique(l)))\n",
    "\n",
    "df_positive['sub_a_b_all'] = sub_pos\n",
    "df_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive.loc[381966].sub_a_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(col(\"total_ocr_dupla\") >= min_itens_interactions)\\\n",
    "       .filter(col(\"relative_pos\") <= max_relative_pos)\\\n",
    "       .filter(col(\"pos_A\") <= max_itens_per_session)\n",
    "\n",
    "df = df.select(\"SessionID\", 'Timestamp', 'ItemID_A', 'ItemID_B', 'relative_pos', \n",
    "                        'total_ocr', 'total_ocr_dupla')\n",
    "\n",
    "df.show(10), df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates(['ItemID_A', 'ItemID_B', 'relative_pos'])\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-with-Pixiedust_Spark-2.3",
   "language": "python",
   "name": "pythonwithpixiedustspark23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
